{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a04b0239-20e8-4834-a839-9d22a9b7d1b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configurações iniciais\n",
    "processo_nome = 'silver_ue_calculation'\n",
    "status_final = 'sucesso'\n",
    "detalhes_log = 'Cálculo da UE e DQ concluídos.'\n",
    "total_records = 0\n",
    "\n",
    "try:\n",
    "    # 1. INICIO DO PROCESSO - LOGGING\n",
    "    spark.sql(f\"\"\"\n",
    "    INSERT INTO pl_delivery_analysis.log_processamento (processo, etapa, status, timestamp, detalhes)\n",
    "    VALUES ('{processo_nome}', 'inicio', 'executando', CURRENT_TIMESTAMP(), 'Iniciando cálculo da UE e DQ checks');\n",
    "    \"\"\")\n",
    "\n",
    "    # 2. LOGICA CORE: CALCULO DA UE (COM DEDUPLICAÇÃO E CASTING)\n",
    "    query_silver = \"\"\"\n",
    "    CREATE OR REPLACE TABLE pl_delivery_analysis.tbl_fact_pedidos_silver AS\n",
    "    WITH constantes AS (\n",
    "        SELECT \n",
    "            0.18 AS comissao_plataforma,\n",
    "            0.70 AS repasse_entregador,\n",
    "            0.02 AS taxa_transacao\n",
    "    ),\n",
    "    -- 1. DEDUPLICAR DELIVERIES: Pega a última tentativa ou a que foi entregue\n",
    "    deliveries_dedup AS (\n",
    "        SELECT \n",
    "            order_id, \n",
    "            driver_id,\n",
    "            delivery_status\n",
    "        FROM (\n",
    "            SELECT \n",
    "                order_id, \n",
    "                driver_id,\n",
    "                delivery_status,\n",
    "                ROW_NUMBER() OVER (\n",
    "                    PARTITION BY order_id \n",
    "                    ORDER BY \n",
    "                        CASE WHEN delivery_status = 'DELIVERED' THEN 1 ELSE 2 END, \n",
    "                        driver_id \n",
    "                ) as rn\n",
    "            FROM pl_delivery_analysis.tbl_fact_deliveries_bronze\n",
    "            WHERE delivery_status = 'DELIVERED'\n",
    "        ) \n",
    "        WHERE rn = 1\n",
    "    ),\n",
    "    -- 2. DEDUPLICAR PAYMENTS: Pega o pagamento principal\n",
    "    payments_dedup AS (\n",
    "        SELECT \n",
    "            order_id, \n",
    "            payment_method\n",
    "        FROM (\n",
    "            SELECT \n",
    "                order_id,\n",
    "                payment_method,\n",
    "                ROW_NUMBER() OVER (\n",
    "                    PARTITION BY order_id \n",
    "                    ORDER BY CAST(payment_amount AS DECIMAL(10,2)) DESC\n",
    "                ) as rn\n",
    "            FROM pl_delivery_analysis.tbl_fact_payments_bronze\n",
    "        ) \n",
    "        WHERE rn = 1\n",
    "    ),\n",
    "    -- 3. JOIN FINAL E VALIDAÇÃO DE ENTRADA\n",
    "    pedidos_limpos AS (\n",
    "        SELECT\n",
    "            t1.order_id,\n",
    "            t1.store_id,\n",
    "            d.driver_id,\n",
    "            t1.created_at AS created_at_ts_str,\n",
    "            p.payment_method,\n",
    "            d.delivery_status,\n",
    "            \n",
    "            -- Casting de STRING para DECIMAL para cálculo\n",
    "            CAST(t1.subtotal AS DECIMAL(10,2)) AS subtotal_bruto,\n",
    "            CAST(t1.delivery_fee AS DECIMAL(10,2)) AS delivery_fee_cliente,\n",
    "            \n",
    "            t4.comissao_plataforma,\n",
    "            t4.repasse_entregador,\n",
    "            t4.taxa_transacao\n",
    "        FROM pl_delivery_analysis.tbl_fact_orders_bronze t1\n",
    "        INNER JOIN deliveries_dedup d ON t1.order_id = d.order_id\n",
    "        INNER JOIN payments_dedup p ON t1.order_id = p.order_id\n",
    "        CROSS JOIN constantes t4\n",
    "        WHERE \n",
    "            -- FILTRO DE DQ: Descartar pedidos com valores monetários nulos ou negativos\n",
    "            CAST(t1.subtotal AS DECIMAL(10,2)) IS NOT NULL AND\n",
    "            CAST(t1.delivery_fee AS DECIMAL(10,2)) IS NOT NULL AND\n",
    "            CAST(t1.subtotal AS DECIMAL(10,2)) >= 0\n",
    "    )\n",
    "    SELECT\n",
    "        order_id,\n",
    "        store_id,\n",
    "        driver_id,\n",
    "        payment_method,\n",
    "        created_at_ts_str,\n",
    "        subtotal_bruto,\n",
    "        delivery_fee_cliente,\n",
    "        (subtotal_bruto + delivery_fee_cliente) AS gmv_total,\n",
    "        (subtotal_bruto * comissao_plataforma) + (delivery_fee_cliente * (1 - repasse_entregador)) AS receita_liquida_plataforma,\n",
    "        (delivery_fee_cliente * repasse_entregador) AS cogs_logistico_simulado,\n",
    "        (subtotal_bruto * taxa_transacao) AS cogs_transacao_simulado,\n",
    "        (\n",
    "            (subtotal_bruto * comissao_plataforma) + (delivery_fee_cliente * (1 - repasse_entregador)) \n",
    "            - (delivery_fee_cliente * repasse_entregador) \n",
    "            - (subtotal_bruto * taxa_transacao)\n",
    "        ) AS lucro_bruto_unitario\n",
    "    FROM pedidos_limpos;\n",
    "    \"\"\"\n",
    "    spark.sql(query_silver)\n",
    "\n",
    "    # Conta o total de registros\n",
    "    total_records = spark.sql(\"SELECT COUNT(*) AS total FROM pl_delivery_analysis.tbl_fact_pedidos_silver\").collect()[0]['total']\n",
    "\n",
    "    # 3. DATA QUALITY CHECKS (APÓS CRIAÇÃO DA SILVER)\n",
    "    print(\"Executando Data Quality Checks...\")\n",
    "\n",
    "    # A. CHECK NULLS (Lucro Bruto Unitário)\n",
    "    df_null = spark.sql(\"\"\"\n",
    "    SELECT CAST(SUM(CASE WHEN lucro_bruto_unitario IS NULL THEN 1 ELSE 0 END) AS DECIMAL(15,2)) AS null_count\n",
    "    FROM pl_delivery_analysis.tbl_fact_pedidos_silver\n",
    "    \"\"\")\n",
    "    null_count = df_null.collect()[0]['null_count']\n",
    "\n",
    "    # B. CHECK NEGATIVOS (Pedidos Não-Rentáveis)\n",
    "    df_neg = spark.sql(\"\"\"\n",
    "    SELECT CAST(SUM(CASE WHEN lucro_bruto_unitario < 0 THEN 1 ELSE 0 END) AS DECIMAL(15,2)) AS neg_count\n",
    "    FROM pl_delivery_analysis.tbl_fact_pedidos_silver\n",
    "    \"\"\")\n",
    "    neg_count = df_neg.collect()[0]['neg_count']\n",
    "\n",
    "    # C. CHECK EXTREMOS (Lucro Bruto > 50% do GMV Total) - Nova Validação de Negócio\n",
    "    df_extremo = spark.sql(\"\"\"\n",
    "    SELECT CAST(SUM(CASE WHEN lucro_bruto_unitario > (gmv_total * 0.50) THEN 1 ELSE 0 END) AS DECIMAL(15,2)) AS extremo_count\n",
    "    FROM pl_delivery_analysis.tbl_fact_pedidos_silver\n",
    "    \"\"\")\n",
    "    extremo_count = df_extremo.collect()[0]['extremo_count']\n",
    "\n",
    "    if total_records > 0:\n",
    "        pct_neg = (neg_count / total_records) * 100\n",
    "        pct_extremo = (extremo_count / total_records) * 100\n",
    "    else:\n",
    "        pct_neg = 0.0\n",
    "        pct_extremo = 0.0\n",
    "\n",
    "    # 4. INSERIR METRICAS (Incluindo a nova métrica de extremo)\n",
    "    spark.sql(f\"\"\"\n",
    "    INSERT INTO pl_delivery_analysis.metricas_qualidade (metrica, valor, data_calculo)\n",
    "    VALUES \n",
    "    ('silver_lucro_bruto_nulls', {null_count}, CURRENT_TIMESTAMP()),\n",
    "    ('silver_pedidos_nao_rentaveis', {pct_neg}, CURRENT_TIMESTAMP()),\n",
    "    ('silver_pedidos_lucro_extremo', {pct_extremo}, CURRENT_TIMESTAMP());\n",
    "    \"\"\")\n",
    "\n",
    "except Exception as e:\n",
    "    status_final = 'falha'\n",
    "    erro_msg = str(e).replace(\"'\", \"\") \n",
    "    detalhes_log = f\"Erro na execução: {erro_msg}\"\n",
    "    print(f\"ERRO CRITICO: {detalhes_log}\")\n",
    "    raise e\n",
    "\n",
    "finally:\n",
    "    # 5. LOG FINAL\n",
    "    spark.sql(f\"\"\"\n",
    "    INSERT INTO pl_delivery_analysis.log_processamento (processo, etapa, status, timestamp, detalhes)\n",
    "    VALUES ('{processo_nome}', 'fim', '{status_final}', CURRENT_TIMESTAMP(), '{detalhes_log} - Registros: {total_records}');\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_02_silver_ue_calculation_dq.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
