{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e37438c4-bb4d-441b-a305-95013dd65de3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Notebook: sql/03_gold_dimensional_model/03_gold_model.ipynb\n",
    "\n",
    "# Configurações iniciais\n",
    "processo_nome = 'gold_dimensional_model'\n",
    "status_final = 'sucesso'\n",
    "detalhes_log = 'Modelagem Gold concluída.'\n",
    "count_fact = 0\n",
    "count_store = 0\n",
    "count_time = 0\n",
    "\n",
    "try:\n",
    "    # 1. LOG INICIAL\n",
    "    spark.sql(f\"\"\"\n",
    "    INSERT INTO pl_delivery_analysis.log_processamento (processo, etapa, status, timestamp, detalhes)\n",
    "    VALUES ('{processo_nome}', 'inicio', 'executando', CURRENT_TIMESTAMP(), 'Iniciando modelagem dimensional Gold');\n",
    "    \"\"\")\n",
    "\n",
    "    # 2. DEFINIR FUNÇÃO DE DATA (UDF)\n",
    "    # Necessária para converter 'M/d/yyyy h:mm:ss a'\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE FUNCTION pl_delivery_analysis.convert_datetime_to_date(datetime_str STRING)\n",
    "    RETURNS DATE\n",
    "    RETURN TO_DATE(\n",
    "        TO_TIMESTAMP(datetime_str, 'M/d/yyyy h:mm:ss a')\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    # 3. CRIAR DIMENSÃO LOJA (Stores + Hubs)\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE pl_delivery_analysis.tbl_dim_store_gold AS\n",
    "    SELECT \n",
    "        s.store_id,\n",
    "        s.store_segment,\n",
    "        s.hub_id,\n",
    "        h.city\n",
    "    FROM pl_delivery_analysis.tbl_dim_stores_bronze s\n",
    "    LEFT JOIN pl_delivery_analysis.tbl_dim_hubs_bronze h ON s.hub_id = h.hub_id;\n",
    "    \"\"\")\n",
    "    count_store = spark.sql(\"SELECT COUNT(*) as total FROM pl_delivery_analysis.tbl_dim_store_gold\").collect()[0]['total']\n",
    "\n",
    "    # 4. CRIAR DIMENSÃO TEMPO\n",
    "    # Extrai datas únicas dos pedidos Silver e cria calendário\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE pl_delivery_analysis.tbl_dim_time_gold AS\n",
    "    SELECT DISTINCT\n",
    "        d.date_key,\n",
    "        YEAR(d.date_key) AS year,\n",
    "        MONTH(d.date_key) AS month,\n",
    "        DAYOFMONTH(d.date_key) AS day,\n",
    "        WEEKDAY(d.date_key) AS day_of_week_num,\n",
    "        CASE \n",
    "            WHEN MONTH(d.date_key) IN (1, 2, 3) THEN 'Q1'\n",
    "            WHEN MONTH(d.date_key) IN (4, 5, 6) THEN 'Q2'\n",
    "            WHEN MONTH(d.date_key) IN (7, 8, 9) THEN 'Q3'\n",
    "            ELSE 'Q4'\n",
    "        END AS quarter\n",
    "    FROM (\n",
    "        SELECT\n",
    "            pl_delivery_analysis.convert_datetime_to_date(created_at_ts_str) AS date_key\n",
    "        FROM pl_delivery_analysis.tbl_fact_pedidos_silver\n",
    "    ) d\n",
    "    WHERE d.date_key IS NOT NULL;\n",
    "    \"\"\")\n",
    "    count_time = spark.sql(\"SELECT COUNT(*) as total FROM pl_delivery_analysis.tbl_dim_time_gold\").collect()[0]['total']\n",
    "\n",
    "    # 5. CRIAR TABELA FATO (Fato Delivery)\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE pl_delivery_analysis.tbl_fato_delivery_gold AS\n",
    "    SELECT\n",
    "        p.order_id,\n",
    "        p.store_id,\n",
    "        p.driver_id,\n",
    "        p.payment_method,\n",
    "        pl_delivery_analysis.convert_datetime_to_date(p.created_at_ts_str) AS order_date_key,\n",
    "        p.subtotal_bruto,\n",
    "        p.delivery_fee_cliente,\n",
    "        p.gmv_total,\n",
    "        p.receita_liquida_plataforma,\n",
    "        p.cogs_logistico_simulado,\n",
    "        p.cogs_transacao_simulado,\n",
    "        p.lucro_bruto_unitario\n",
    "    FROM\n",
    "        pl_delivery_analysis.tbl_fact_pedidos_silver p;\n",
    "    \"\"\")\n",
    "    \n",
    "    # Otimização Z-ORDER para performance no Power BI\n",
    "    spark.sql(\"\"\"\n",
    "    OPTIMIZE pl_delivery_analysis.tbl_fato_delivery_gold\n",
    "    ZORDER BY (order_date_key, store_id);\n",
    "    \"\"\")\n",
    "\n",
    "    count_fact = spark.sql(\"SELECT COUNT(*) as total FROM pl_delivery_analysis.tbl_fato_delivery_gold\").collect()[0]['total']\n",
    "\n",
    "    # 6. COMENTÁRIOS NA TABELA (Documentação)\n",
    "    spark.sql(\"\"\"\n",
    "    COMMENT ON TABLE pl_delivery_analysis.tbl_fato_delivery_gold IS 'Tabela fato principal com métricas de Unit Economics. ZORDERed por data e loja.'\n",
    "    \"\"\")\n",
    "\n",
    "except Exception as e:\n",
    "    status_final = 'falha'\n",
    "    erro_msg = str(e).replace(\"'\", \"\")\n",
    "    detalhes_log = f\"Erro na modelagem Gold: {erro_msg}\"\n",
    "    print(f\"ERRO CRÍTICO: {detalhes_log}\")\n",
    "    raise e\n",
    "\n",
    "finally:\n",
    "    # 7. LOG FINAL\n",
    "    msg_final = f\"{detalhes_log} | Fatos: {count_fact}, Lojas: {count_store}, Datas: {count_time}\"\n",
    "    \n",
    "    spark.sql(f\"\"\"\n",
    "    INSERT INTO pl_delivery_analysis.log_processamento (processo, etapa, status, timestamp, detalhes)\n",
    "    VALUES ('{processo_nome}', 'fim', '{status_final}', CURRENT_TIMESTAMP(), '{msg_final}');\n",
    "    \"\"\")\n",
    "    \n",
    "    print(msg_final)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_03_gold_model.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
